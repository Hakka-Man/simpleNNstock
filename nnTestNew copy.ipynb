{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform = transforms.Compose(\n",
    "#     [transforms.ToTensor(),\n",
    "#      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# batch_size = 4\n",
    "\n",
    "# trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "#                                         download=True, transform=transform)\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "#                                           shuffle=True, num_workers=2)\n",
    "\n",
    "# testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "#                                        download=True, transform=transform)\n",
    "# testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "#                                          shuffle=False, num_workers=2)\n",
    "\n",
    "# classes = ('plane', 'car', 'bird', 'cat',\n",
    "#            'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'processedDataset/'\n",
    "\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "        i = 0\n",
    "        tempData = os.listdir(directory)\n",
    "        while i < 16000:\n",
    "            f = os.path.join(directory, tempData[i])\n",
    "            if torch.any(torch.isnan(torch.load(f))):\n",
    "                print(f + \" contains nan\")\n",
    "                continue\n",
    "            else:\n",
    "                x = torch.load(f).float().to(device)\n",
    "                x = torch.nn.functional.normalize(x, p=2.0, dim = 1)\n",
    "                label = int(torch.load(f)[0].sum() > torch.load(f)[1].sum())\n",
    "                self.data.append([x, label])\n",
    "                i += 1\n",
    "                # if filename.split('-')[2].replace(\".pt\",\"\") == '1':\n",
    "                #     Y.append(torch.tensor([0,1]).float())\n",
    "                # else:\n",
    "                #     Y.append(torch.tensor([1,0]).float())\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i][0][0:2], self.data[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestStockDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.data = []\n",
    "        i = 0\n",
    "        tempData = os.listdir(directory)\n",
    "        tempData.reverse()\n",
    "        while i < 1600:\n",
    "            f = os.path.join(directory, tempData[i])\n",
    "            if torch.any(torch.isnan(torch.load(f))):\n",
    "                print(f + \" contains nan\")\n",
    "                continue\n",
    "            else:\n",
    "                x = torch.load(f).float().to(device)\n",
    "                x = torch.nn.functional.normalize(x, p=2.0, dim = 1)\n",
    "                label = int(torch.load(f)[0][0].sum() > torch.load(f)[1][0].sum())\n",
    "                self.data.append([x, label])\n",
    "                i += 1\n",
    "                # if filename.split('-')[2].replace(\".pt\",\"\") == '1':\n",
    "                #     Y.append(torch.tensor([0,1]).float())\n",
    "                # else:\n",
    "                #     Y.append(torch.tensor([1,0]).float())\n",
    "            \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i][0][0:2], self.data[i][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "stockDataset = StockDataset()\n",
    "testDataset = TestStockDataset()\n",
    "trainloader = torch.utils.data.DataLoader(stockDataset, batch_size=batch_size, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testDataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(22 * 2, 2)\n",
    "        # self.fc2 = nn.Linear(120, 84)\n",
    "        # self.fc3 = nn.Linear(84, 2)\n",
    "    def forward(self, x):\n",
    "        # x = self.pool(F.relu(self.conv1(x)))\n",
    "        # x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = self.fc1(x)\n",
    "        # x = F.relu(self.fc1(x))\n",
    "        # x = F.relu(self.fc2(x))\n",
    "        # x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "if device == 'cuda':\n",
    "    net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.003, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100: loss: 0.5757992094755173\n",
      "epoch 200: loss: 0.5393297301530838\n",
      "epoch 300: loss: 0.5181512573957443\n",
      "epoch 400: loss: 0.5036199244260788\n",
      "epoch 500: loss: 0.4929525636434555\n",
      "epoch 600: loss: 0.4846720849275589\n",
      "epoch 700: loss: 0.47799241042137147\n",
      "epoch 800: loss: 0.4724190791845322\n",
      "epoch 900: loss: 0.46778318071365355\n",
      "epoch 1000: loss: 0.4638344588279724\n",
      "epoch 1100: loss: 0.46031678378582\n",
      "epoch 1200: loss: 0.45722998297214507\n",
      "epoch 1300: loss: 0.45453360152244565\n",
      "epoch 1400: loss: 0.4520802807807922\n",
      "epoch 1500: loss: 0.4498594862222671\n",
      "epoch 1600: loss: 0.44795352482795714\n",
      "epoch 1700: loss: 0.4461701581478119\n",
      "epoch 1800: loss: 0.444527016043663\n",
      "epoch 1900: loss: 0.44305200028419495\n",
      "epoch 2000: loss: 0.4416123623847961\n",
      "epoch 2100: loss: 0.44035154628753664\n",
      "epoch 2200: loss: 0.43914720380306244\n",
      "epoch 2300: loss: 0.43796308076381685\n",
      "epoch 2400: loss: 0.43695631849765776\n",
      "epoch 2500: loss: 0.4360013282299042\n",
      "epoch 2600: loss: 0.4348953629732132\n",
      "epoch 2700: loss: 0.43420226669311524\n",
      "epoch 2800: loss: 0.433361364364624\n",
      "epoch 2900: loss: 0.43265058994293215\n",
      "epoch 3000: loss: 0.43192181074619296\n",
      "epoch 3100: loss: 0.43120278799533845\n",
      "epoch 3200: loss: 0.4305915999412537\n",
      "epoch 3300: loss: 0.42990975964069367\n",
      "epoch 3400: loss: 0.4293511135578156\n",
      "epoch 3500: loss: 0.42873196470737457\n",
      "epoch 3600: loss: 0.42825636970996855\n",
      "epoch 3700: loss: 0.42774711787700653\n",
      "epoch 3800: loss: 0.4272361069917679\n",
      "epoch 3900: loss: 0.42685120236873625\n",
      "epoch 4000: loss: 0.42631207406520844\n",
      "epoch 4100: loss: 0.42591782367229464\n",
      "epoch 4200: loss: 0.4254886021614075\n",
      "epoch 4300: loss: 0.4251036741733551\n",
      "epoch 4400: loss: 0.4246502437591553\n",
      "epoch 4500: loss: 0.42433545780181886\n",
      "epoch 4600: loss: 0.4239833071231842\n",
      "epoch 4700: loss: 0.42358427369594576\n",
      "epoch 4800: loss: 0.42333388233184815\n",
      "epoch 4900: loss: 0.42297371017932894\n",
      "epoch 5000: loss: 0.42270312547683714\n",
      "epoch 5100: loss: 0.42238383495807647\n",
      "epoch 5200: loss: 0.4220817544460297\n",
      "epoch 5300: loss: 0.42184629929065703\n",
      "epoch 5400: loss: 0.42154754066467287\n",
      "epoch 5500: loss: 0.4213002068996429\n",
      "epoch 5600: loss: 0.42099658930301664\n",
      "epoch 5700: loss: 0.42078322291374204\n",
      "epoch 5800: loss: 0.42047273921966555\n",
      "epoch 5900: loss: 0.4202436721324921\n",
      "epoch 6000: loss: 0.41999808740615846\n",
      "epoch 6100: loss: 0.41985280001163483\n",
      "epoch 6200: loss: 0.4197175717353821\n",
      "epoch 6300: loss: 0.4194075232744217\n",
      "epoch 6400: loss: 0.41918685322999955\n",
      "epoch 6500: loss: 0.41889559805393217\n",
      "epoch 6600: loss: 0.4188284180164337\n",
      "epoch 6700: loss: 0.41859188985824586\n",
      "epoch 6800: loss: 0.41841122388839724\n",
      "epoch 6900: loss: 0.41824038231372834\n",
      "epoch 7000: loss: 0.418032466173172\n",
      "epoch 7100: loss: 0.4178784635066986\n",
      "epoch 7200: loss: 0.4177518150806427\n",
      "epoch 7300: loss: 0.41755925297737123\n",
      "epoch 7400: loss: 0.4173200377225876\n",
      "epoch 7500: loss: 0.4172300500869751\n",
      "epoch 7600: loss: 0.41697274577617643\n",
      "epoch 7700: loss: 0.41692759323120115\n",
      "epoch 7800: loss: 0.4168013850450516\n",
      "epoch 7900: loss: 0.41659668922424314\n",
      "epoch 8000: loss: 0.4165260539650917\n",
      "epoch 8100: loss: 0.41636697614192963\n",
      "epoch 8200: loss: 0.4161924431324005\n",
      "epoch 8300: loss: 0.4160404345989227\n",
      "epoch 8400: loss: 0.4159918923377991\n",
      "epoch 8500: loss: 0.4158790386915207\n",
      "epoch 8600: loss: 0.4157497522830963\n",
      "epoch 8700: loss: 0.4155823771953583\n",
      "epoch 8800: loss: 0.41547515416145325\n",
      "epoch 8900: loss: 0.41535441422462466\n",
      "epoch 9000: loss: 0.41524356627464293\n",
      "epoch 9100: loss: 0.4150438561439514\n",
      "epoch 9200: loss: 0.4149871438741684\n",
      "epoch 9300: loss: 0.414913751244545\n",
      "epoch 9400: loss: 0.4148026112318039\n",
      "epoch 9500: loss: 0.41466849732398986\n",
      "epoch 9600: loss: 0.41459383529424665\n",
      "epoch 9700: loss: 0.41445731568336486\n",
      "epoch 9800: loss: 0.4144596728682518\n",
      "epoch 9900: loss: 0.41427206063270566\n",
      "epoch 10000: loss: 0.41416847008466723\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from cProfile import label, run\n",
    "import string\n",
    "\n",
    "\n",
    "for epoch in range(10000):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        if device == 'cuda':\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    if epoch % 100 == 99:    # print every 2000 mini-batches\n",
    "        print(f'epoch {epoch + 1}: loss: {running_loss /16000*batch_size}')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "if device == 'cuda':\n",
    "    net = net.cuda()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "stocks, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1])\n",
      "tensor([0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
      "        0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
      "        0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "print(predicted)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 47 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        if device == 'cuda':\n",
    "            labels = labels.cuda()\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('simpleNNstock')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d30658fedb253a0fe01946805c369386cc92ad4c6d3b31839e09b4dcbfacc89a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
